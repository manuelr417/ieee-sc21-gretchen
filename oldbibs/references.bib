%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Manuel Rodriguez at 2019-11-11 12:29:44 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@article{DBLP:journals/corr/abs-1809-05053,
	Archiveprefix = {arXiv},
	Author = {Alexis Conneau and Guillaume Lample and Ruty Rinott and Adina Williams and Samuel R. Bowman and Holger Schwenk and Veselin Stoyanov},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1809-05053},
	Date-Added = {2019-11-11 12:29:34 -0400},
	Date-Modified = {2019-11-11 12:29:34 -0400},
	Eprint = {1809.05053},
	Journal = {CoRR},
	Timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
	Title = {{XNLI:} Evaluating Cross-lingual Sentence Representations},
	Url = {http://arxiv.org/abs/1809.05053},
	Volume = {abs/1809.05053},
	Year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1809.05053}}

@article{Conneau:2018aa,
	Abstract = {State-of-the-art natural language processing systems rely on supervision in the form of annotated data to learn competent models. These models are generally trained on data in a single language (usually English), and cannot be directly used beyond that language. Since collecting data in every language is not realistic, there has been a growing interest in cross-lingual language understanding (XLU) and low-resource cross-language transfer. In this work, we construct an evaluation set for XLU by extending the development and test sets of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15 languages, including low-resource languages such as Swahili and Urdu. We hope that our dataset, dubbed , will catalyze research in cross-lingual sentence understanding by providing an informative standard evaluation task. In addition, we provide several baselines for multilingual sentence understanding, including two based on machine translation systems, and two that use parallel data to train aligned multilingual bag-of-words and LSTM encoders. We find that  represents a practical and challenging evaluation suite, and that directly translating the test data yields the best performance among available baselines.},
	Author = {Alexis Conneau and Guillaume Lample and Ruty Rinott and Adina Williams and Samuel R. Bowman and Holger Schwenk and Veselin Stoyanov},
	Date-Added = {2019-11-11 12:28:34 -0400},
	Date-Modified = {2019-11-11 12:28:34 -0400},
	Eprint = {1809.05053},
	Month = {09},
	Title = {: Evaluating Cross-lingual Sentence Representations},
	Url = {https://arxiv.org/pdf/1809.05053.pdf},
	Year = {2018},
	Bdsk-Url-1 = {https://arxiv.org/pdf/1809.05053.pdf},
	Bdsk-Url-2 = {https://arxiv.org/abs/1809.05053}}

@inproceedings{8622504,
	Author = {C. C. {Garzon-Alfonso} and M. {Rodriguez-Martinez}},
	Booktitle = {2018 IEEE International Conference on Big Data (Big Data)},
	Doi = {10.1109/BigData.2018.8622504},
	Keywords = {Big Data;data acquisition;data warehouses;medical information systems;meta data;pattern classification;recurrent neural nets;social networking (online);medical condition;THS system;Health Surveillance system;Twitter Health Surveillance application framework;health officials;big data warehouse;Data Acquisition;Tweet Classification;Big Data Warehousing;medical terms;Twitter;Big Data;Tools;Diseases;Metadata;big data analytics;deep learning;disease detection},
	Month = {Dec},
	Pages = {1647-1654},
	Title = {Twitter Health Surveillance (THS) System},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/BigData.2018.8622504}}

@inproceedings{8029348,
	Author = {M. {Rodriguez-Martinez}},
	Booktitle = {2017 IEEE International Congress on Big Data (BigData Congress)},
	Doi = {10.1109/BigDataCongress.2017.55},
	Keywords = {Big Data;data analysis;health care;Java;medical information systems;parallel programming;social networking (online);software tools;Twitter health surveillance system;THS system;social media;public opinion;big data analytics;single-server solutions;software tools;Java/Scala programs;Python scripts;THS application framework;user-defined functions;Apache Hadoop Ecosystem;Twitter;Dictionaries;Picture archiving and communication systems;Big Data;Monitoring;Sparks;big data analytics;streaming;use-defined functions;Twitter;social media},
	Month = {June},
	Pages = {376-383},
	Title = {Experiences with the Twitter Health Surveillance (THS) System},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/BigDataCongress.2017.55}}

@url{cite-key,
	Annote = {@INPROCEEDINGS{8029348, 
author={M. {Rodr{\'\i}guez-Martinez}}, 
booktitle={2017 IEEE International Congress on Big Data (BigData Congress)}, 
title={Experiences with the Twitter Health Surveillance (THS) System}, 
year={2017}, 
volume={}, 
number={}, 
pages={376-383}, 
keywords={Big Data;data analysis;health care;Java;medical information systems;parallel programming;social networking (online);software tools;Twitter health surveillance system;THS system;social media;public opinion;big data analytics;single-server solutions;software tools;Java/Scala programs;Python scripts;THS application framework;user-defined functions;Apache Hadoop Ecosystem;Twitter;Dictionaries;Picture archiving and communication systems;Big Data;Monitoring;Sparks;big data analytics;streaming;use-defined functions;Twitter;social media}, 
doi={10.1109/BigDataCongress.2017.55}, 
ISSN={}, 
month={June},}},
	Date-Added = {2019-06-06 14:05:51 -0400},
	Date-Modified = {2019-06-06 14:06:15 -0400}}

@book{Shai2014,
	Author = {Shai Shalev-Shwartz and Shai Ben-David},
	Publisher = {Cambridge University Press},
	Title = {Understanding Machine Learning: From Theory to Algorithms},
	Year = {2014}}

@book{Nilsson1998,
	Author = {Nils J. Nilson},
	Publisher = {Stanford University},
	Title = {Introduction to Machine Learning},
	Url = {http://ai.stanford.edu/~nilsson/MLBOOK.pdf},
	Year = {1998},
	Bdsk-Url-1 = {http://ai.stanford.edu/~nilsson/MLBOOK.pdf}}

@book{Goodfellow2016,
	Author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	Publisher = {MIT Press},
	Title = {Deep Learning},
	Url = {http://www.deeplearningbook.org},
	Year = {2016},
	Bdsk-Url-1 = {http://www.deeplearningbook.org}}

@book{Russell2010,
	Author = {Russell, Stuart J. and Norvig, Peter},
	Place = {Upper Saddle River},
	Publisher = {Pearson},
	Title = {Artificial intelligence: a modern approach},
	Year = {2010}}

@book{Kelleher2015,
	Author = {John D. Kelleher, Brian Mac Namee, Aoife D'Arcy},
	Publisher = {The MIT Press},
	Title = {Fundamentals of Machine Learning for Predictive Data Analytics},
	Year = {2015}}

@book{Nevala2017,
	Author = {Kimberly Nevala},
	Publisher = {SAS Institute Inc.},
	Title = {The Machine Learning Primer},
	Year = {2016}}

@book{Gurney2004,
	Author = {Kevin Gurney},
	Publisher = {Taylor and Francis e-Library},
	Title = {An Introduction to Neural Networks},
	Year = {2004}}

@book{Kriesel2005,
	Author = {David Kriesel},
	Publisher = {dkriesel},
	Title = {A Brief Introduction to Neural Networks},
	Year = {2005}}

@book{Indurkhya2010,
	Author = {Nitin Iindukhya Fred J. Damerau},
	Publisher = {CRC Press},
	Title = {Handbook of Natural Language Processing},
	Year = {2010}}

@inproceedings{Halibas2018,
	Abstract = {In the recent years, social networks in business are gaining unprecedented popularity because of their potential for business growth. Companies can know more about consumers' sentiments towards their products and services, and use it to better understand the market and improve their brand. Thus, companies regularly reinvent their marketing strategies and campaigns to fit consumers' preferences. Social analysis harnesses and utilizes the vast volume of data in social networks to mine critical data for strategic decision making. It uses machine learning techniques and tools in determining patterns and trends to gain actionable insights. This paper selected a popular food brand to evaluate a given stream of customer comments on Twitter. Several metrics in classification and clustering of data were used for analysis. A Twitter API is used to collect twitter corpus and feed it to a Binary Tree classifier that will discover the polarity lexicon of English tweets, whether positive or negative. A k-means clustering technique is used to group together similar words in tweets in order to discover certain business value. This paper attempts to discuss the technical and business perspectives of text mining analysis of Twitter data and recommends appropriate future opportunities in developing this emerging field.},
	Author = {A. S. Halibas and A. S. Shaffi and M. A. K. V. Mohamed},
	Booktitle = {2018 Majan International Conference (MIC)},
	Doi = {10.1109/MINTC.2018.8363162},
	Keywords = {application program interfaces;business data processing;data mining;decision making;learning (artificial intelligence);pattern clustering;social networking (online);text analysis;text classification;business analytics;social networks;business growth;marketing strategies;social analysis harnesses;strategic decision making;machine learning techniques;Twitter API;twitter corpus;clustering technique;business value;technical business;text mining analysis;Twitter data clustering;critical data mining;food brand;Twitter;Sentiment analysis;Decision trees;Companies;Text categorization;Twitter;Sentiment Analysis;Decision Tree;k-means;Social Media},
	Month = {March},
	Pages = {1-7},
	Title = {Application of text classification and clustering of Twitter data for business analytics},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/MINTC.2018.8363162}}

@inproceedings{Long2015,
	Abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build ``fully convolutional'' networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet [20], the VGG net [31], and GoogLeNet [32]) into fully convolutional networks and transfer their learned representations by fine-tuning [3] to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.},
	Author = {J. Long and E. Shelhamer and T. Darrell},
	Booktitle = {2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	Doi = {10.1109/CVPR.2015.7298965},
	Issn = {1063-6919},
	Keywords = {image classification;image segmentation;inference mechanisms;learning (artificial intelligence);fully convolutional networks;semantic segmentation;visual models;pixels-to-pixels;inference;learning;contemporary classification networks;PASCAL VOC;NYUDv2;SIFT flow;Semantics;Training;Convolution;Image segmentation;Computer architecture;Deconvolution;Adaptation models},
	Month = {June},
	Pages = {3431-3440},
	Title = {Fully convolutional networks for semantic segmentation},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/CVPR.2015.7298965}}

@misc{Graves2017,
	Author = {Alex Graves},
	Publisher = {University of Toronto Press},
	Title = {Supervised Sequence Labelling with Recurrent Neural Networks},
	Url = {https://www.cs.toronto.edu/~graves/preprint.pdf},
	Year = {2010},
	Bdsk-Url-1 = {https://www.cs.toronto.edu/~graves/preprint.pdf}}

@inproceedings{Xavier2018,
	Abstract = {Long short-term memory recurrent neural networks have been proved to be especially useful for learning sequences comprising longer-term patterns of unknown length as they are able to preserve long-term memory. The learning of higher level temporal features could be achieved by stacking recurrent hidden layers for faster learning with sparser representations. In this work, we propose a novel approach to data driven fault detection and diagnosis of a chemical process. The method employs a state-of-the-art deep-learning technique, viz. the long short-term memory recurrent neural network. An application of the proposed approach is performed with realistic simulated data from a chemical process literature benchmark. Results point out an excellent performance when compared to already published linear and nonlinear fault detection and diagnosis methods.},
	Author = {G. M. Xavier and J. M. de Seixas},
	Booktitle = {2018 International Joint Conference on Neural Networks (IJCNN)},
	Doi = {10.1109/IJCNN.2018.8489385},
	Issn = {2161-4407},
	Keywords = {chemical engineering computing;fault diagnosis;learning (artificial intelligence);recurrent neural nets;chemical process;long short-term memory recurrent neural network;longer-term patterns;recurrent hidden layers;data driven fault detection;deep-learning technique;fault diagnosis;higher level temporal features;Recurrent neural networks;Feeds;Process control;Chemical processes;Inductors;Cooling;deep networks;recurrent neural network;long short-term memory;fault detection and diagnosis;Tennessee Eastman chemical process},
	Month = {July},
	Pages = {1-8},
	Title = {Fault Detection and Diagnosis in a Chemical Process using Long Short-Term Memory Recurrent Neural Network},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/IJCNN.2018.8489385}}

@inproceedings{Chandra2017,
	Abstract = {The paper proposes a new method for improving the performance of Recurrent Neural Networks. The proposed method uses two parallel recurrent layers which execute independent of each other. The final output of recurrent layer at any time step is computed as the mean of the modulus of the output of these two layers. The proposed method attempts to overcome the limitations of the existing Recurrent Neural Networks with regard to the flow of gradient. Comparative performance of the proposed method has been carried out with Long Short Term Memory (LSTM) and Identity initialized RNN (IRNN), the latest improved version of RNN for classification of images. On benchmark image datasets, it has been shown that the proposed method outperforms both IRNN and LSTM.},
	Author = {B. Chandra and R. K. Sharma},
	Booktitle = {2017 International Joint Conference on Neural Networks (IJCNN)},
	Doi = {10.1109/IJCNN.2017.7966083},
	Issn = {2161-4407},
	Keywords = {image classification;recurrent neural nets;recurrent neural network;image classification;parallel recurrent layers;long short term memory;LSTM;identity initialized RNN;IRNN;benchmark image datasets;Recurrent neural networks;Neurons;Logic gates;Training;Standards;Backpropagation;Benchmark testing;Recurrent Neural Network;Deep Learning;Activation Function},
	Month = {May},
	Pages = {1904-1907},
	Title = {On improving recurrent neural network for image classification},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/IJCNN.2017.7966083}}

@inproceedings{Dai2017,
	Abstract = {Social media provide a low-cost alternative source for public health surveillance and health-related classification plays an important role to identify useful information. In this paper, we summarized the recent classification methods using social media in public health. These methods rely on bag-of-words (BOW) model and have difficulty grasping the semantic meaning of texts. Unlike these methods, we present a word embedding based clustering method. Word embedding is one of the strongest trends in Natural Language Processing (NLP) at this moment. It learns the optimal vectors from surrounding words and the vectors can represent the semantic information of words. A tweet can be represented as a few vectors and divided into clusters of similar words. According to similarity measures of all the clusters, the tweet can then be classified as related or unrelated to a topic (e.g., influenza). Our simulations show a good performance and the best accuracy achieved was 87.1%. Moreover, the proposed method is unsupervised. It does not require labor to label training data and can be readily extended to other classification problems or other diseases.},
	Author = {X. Dai and M. Bikdash and B. Meyer},
	Booktitle = {SoutheastCon 2017},
	Doi = {10.1109/SECON.2017.7925400},
	Issn = {1558-058X},
	Keywords = {diseases;health care;learning (artificial intelligence);medical computing;natural language processing;pattern classification;pattern clustering;social networking (online);vectors;word processing;social media;public health surveillance;word embedding based clustering method;Twitter classification;health-related classification;bag-of-words;BOW model;text semantic meaning;natural language processing;NLP;optimal vector learning;word clusters;diseases;Public healthcare;Natural language processing;Diseases;Support vector machines;Surveillance;Twitter;Unsupervised Classification;Public Health;Twitter;Social Network;Big data;Surveillance;Word Embeddings;Word2Vec;Machine learning;Natural Language Processing;Clustering Process;Similarity Measure},
	Month = {March},
	Pages = {1-7},
	Title = {From social media to public health surveillance: Word embedding based clustering method for twitter classification},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/SECON.2017.7925400}}

@inproceedings{Ahuja2017,
	Abstract = {Twitter is a social media platform is a great place where people from all parts of the world can make their opinions heard. Twitter produces around 500 million of tweets daily which amounts to about 8TB of data. The data generated in twitter can be very useful if analyzed as we can extract important information via opinion mining. Opinions about any news or launch of a product or a certain kind of trend can be observed well in twitter data. The main aim of sentiment analysis (or opinion mining) is to discover emotion, opinion, subjectivity and attitude from a natural text. In twitter sentiment analysis, we categorize tweets into positive and negative sentiment. Clustering is a protean procedure in which identically resembled objects are grouped together and form a pack or cluster. We conducted a study and found out that the use of clustering can quickly and efficiently distinguish tweets on the basis of their sentiment scores and can find weekly and strongly positive or negative tweets when clustered with results of different dictionaries. This paper surveys different approaches of clustering with respect to sentiment analysis and presents a way to find relationships between the tweets on the basis of polarity and subjectivity.},
	Author = {S. Ahuja and G. Dubey},
	Booktitle = {2017 2nd International Conference on Telecommunication and Networks (TEL-NET)},
	Doi = {10.1109/TEL-NET.2017.8343568},
	Keywords = {data mining;pattern clustering;sentiment analysis;social networking (online);social media platform;positive sentiment;negative sentiment;Twitter data;Twitter sentiment analysis;opinion mining;clustering;Clustering algorithms;Sentiment analysis;Twitter;Data mining;Dictionaries;Classification algorithms;Elbow;Cluster;Opinions;Sentiments;Twitter},
	Month = {Aug},
	Pages = {1-5},
	Title = {Clustering and sentiment analysis on Twitter data},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/TEL-NET.2017.8343568}}

@inproceedings{Wang2008,
	Abstract = {The task of clustering is to identify classes of similar objects among a set of objects. The definition of similarity varies from one clustering model to another. However, in most of these models the concept of similarity is often based on such metrics as Manhattan distance, Euclidean distance or other Lp distances. In other words, similar objects must have close values in at least a set of dimensions. In this paper, we explore a more general type of similarity. Under the pCluster model we proposed, two objects are similar if they exhibit a coherent pattern on a subset of dimensions. The new similarity concept models a wide range of applications. For instance, in DNA microarray analysis, the expression levels of two genes may rise and fall synchronously in response to a set of environmental stimuli. Although the magnitude of their expression levels may not be close, the patterns they exhibit can be very much alike. Discovery of such clusters of genes is essential in revealing significant connections in gene regulatory networks. E-commerce applications, such as collaborative filtering, can also benefit from the new model, because it is able to capture not only the closeness of values of certain leading indicators but also the closeness of (purchasing, browsing, etc.) patterns exhibited by the customers. In addition to the novel similarity model, this paper also introduces an effective and efficient algorithm to detect such clusters, and we perform tests on several real and synthetic data sets to show its performance.},
	Author = {Haixun Wang and Jian Pei},
	Booktitle = {JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY},
	Keywords = {data mining, clustering, pattern similarity},
	Month = {May},
	Pages = {481-496},
	Title = {Clustering by Pattern Similarity},
	Year = {2008}}

@inproceedings{Shalini2018,
	Author = {Shalini L and Gopali Naga Sravya},
	Booktitle = {International Research Journal of Engineering and Technology (IRJET)},
	Month = {Mar},
	Number = {03},
	Pages = {2074-2077},
	Title = {Analysis of Health-Tweets using K-means clustering},
	Volume = {05},
	Year = {2018}}

@misc{Brownlee2017,
	Author = {Jason Brownlee},
	Journal = {Deep Learning for Natural Language Processing},
	Month = {10},
	Publisher = {Machine Learning Mastery},
	Title = {A Gentle Introduction to the Bag-of-Words Model},
	Url = {https://machinelearningmastery.com/gentle-introduction-bag-words-model/},
	Year = {2017},
	Bdsk-Url-1 = {https://machinelearningmastery.com/gentle-introduction-bag-words-model/}}

@inproceedings{Tripathy2014,
	Acmid = {2567694},
	Address = {New York, NY, USA},
	Articleno = {7},
	Author = {Tripathy, Rudra M. and Sharma, Shashank and Joshi, Sachindra and Mehta, Sameep and Bagchi, Amitabha},
	Booktitle = {Proceedings of the 1st IKDD Conference on Data Sciences},
	Doi = {10.1145/2567688.2567694},
	Isbn = {978-1-4503-2475-5},
	Keywords = {Clustering, Social Networks, Twitter, Wikipedia},
	Location = {Delhi, India},
	Numpages = {5},
	Pages = {7:1--7:5},
	Publisher = {ACM},
	Series = {CoDS '14},
	Title = {Theme Based Clustering of Tweets},
	Url = {http://doi.acm.org/10.1145/2567688.2567694},
	Year = {2014},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2567688.2567694},
	Bdsk-Url-2 = {https://doi.org/10.1145/2567688.2567694}}

@inproceedings{Lin2013,
	Abstract = {The classification of consumable media by mining relevant text for their identifying features is a subjective process. Previous attempts to perform this type of feature mining have generally been limited in scope due to having limited access to user data. Many of these studies used human domain knowledge to evaluate the accuracy of features extracted using these methods. In this paper, we mine book review text to identify nontrivial features of a set of similar books. We make comparisons between books by looking for books that share characteristics, ultimately performing clustering on the books in our data set. We use the same mining process to identify a corresponding set of characteristics in users. Finally, we evaluate the quality of our methods by examining the correlation between our similarity metric, and user ratings.},
	Author = {E. Lin and S. Fang and J. Wang},
	Booktitle = {2013 27th International Conference on Advanced Information Networking and Applications Workshops},
	Doi = {10.1109/WAINA.2013.172},
	Keywords = {data mining;pattern classification;pattern clustering;publishing;text analysis;online book review mining;sentimental clustering;consumable media classification;text mining;feature mining;human domain knowledge;similarity metric;user rating;Book reviews;Correlation;Text mining;Databases;Computers;Knowledge discovery;clustering;online reviews;text mining;sentiment analysis;clustering},
	Month = {March},
	Pages = {179-184},
	Title = {Mining Online Book Reviews for Sentimental Clustering},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.1109/WAINA.2013.172}}

@inproceedings{Cheong2010,
	Abstract = {Timely detection of hidden patterns is the key for the analysis and estimating of driving determinants for mission critical decision making. This study applies Cheong and Lee's ``context-aware'' content analysis framework to extract latent properties from Twitter messages (tweets). In addition, we incorporate an unsupervised Self-organizing Feature Map (SOM) as a machine learning-based clustering tool that has not been investigated in the context of opinion mining and sentimental analysis using microblogging. Our experimental results reveal the detection of interesting patterns for topics of interest which are latent and cannot be easily detected from the observed tweets without the aid of machine learning tools.},
	Author = {M. Cheong and V. Lee},
	Booktitle = {2010 20th International Conference on Pattern Recognition},
	Doi = {10.1109/ICPR.2010.765},
	Issn = {1051-4651},
	Keywords = {decision making;pattern clustering;social networking (online);pattern detection;twitter intratopic user;message clustering;decision making;context-aware content analysis framework;Twitter messages;self-organizing feature map;machine learning-based clustering tool;opinion mining;sentimental analysis;microblogging;Twitter;Visualization;Media;Nominations and elections;Communities;Clustering algorithms;Online documents;Group interaction: analysis of verbal and non-verbal communication;Pattern recognition systems and applications},
	Month = {Aug},
	Pages = {3125-3128},
	Title = {A Study on Detecting Patterns in Twitter Intra-topic User and Message Clustering},
	Year = {2010},
	Bdsk-Url-1 = {https://doi.org/10.1109/ICPR.2010.765}}

@misc{Tensor2019,
	Author = {Google},
	Journal = {TensorFlow},
	Title = {Get Started with TensorFlow},
	Url = {https://www.tensorflow.org/tutorials/},
	Year = {2019},
	Bdsk-Url-1 = {https://www.tensorflow.org/tutorials/}}

@misc{Keras2019,
	Author = {Keras},
	Journal = {Keras Documentation},
	Title = {Keras: The Python Deep Learning library},
	Url = {https://keras.io/},
	Year = {2019},
	Bdsk-Url-1 = {https://keras.io/}}

@misc{Cuda2019,
	Author = {NVIDIA},
	Journal = {CUDA Documentation},
	Title = {NVIDIA Accelerated Computing: CUDA Zone},
	Url = {https://developer.nvidia.com/cuda-zone/},
	Year = {2019},
	Bdsk-Url-1 = {https://developer.nvidia.com/cuda-zone/}}

@misc{Hadoop2019,
	Author = {Apache},
	Journal = {Apache hadoop Documentation},
	Title = {Apache Hadoop},
	Url = {https://hadoop.apache.org/},
	Year = {2019},
	Bdsk-Url-1 = {https://hadoop.apache.org/}}

@misc{Hive2019,
	Author = {Apache},
	Journal = {Apache Hive TM},
	Title = {Getting Started With Apache Hive Software},
	Url = {https://hive.apache.org/},
	Year = {2019},
	Bdsk-Url-1 = {https://hive.apache.org/}}

@misc{Kafka2019,
	Author = {Apache},
	Journal = {Apache Kafka Introduction},
	Title = {Apache Kafka{\textregistered} is a distributed streaming platform. What exactly does that mean?},
	Url = {https://kafka.apache.org/intro},
	Year = {2019},
	Bdsk-Url-1 = {https://kafka.apache.org/intro}}

@misc{Spark2019,
	Author = {Apache},
	Journal = {Apache Spark Overview},
	Title = {Spark Overview},
	Url = {https://spark.apache.org/docs/latest/},
	Year = {2019},
	Bdsk-Url-1 = {https://spark.apache.org/docs/latest/}}

@misc{Stanford2019,
	Author = {Andrew Ng},
	Journal = {Coursera},
	Title = {Machine Learning},
	Url = {https://www.coursera.org/learn/machine-learning},
	Year = {2019},
	Bdsk-Url-1 = {https://www.coursera.org/learn/machine-learning}}

@article{Mikolov2013,
	Author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, G.s and Dean, Jeffrey},
	Journal = {Advances in Neural Information Processing Systems},
	Month = {10},
	Title = {Distributed Representations of Words and Phrases and their Compositionality},
	Volume = {26},
	Year = {2013}}

@inproceedings{Pennington2014,
	Author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
	Booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
	Pages = {1532--1543},
	Title = {GloVe: Global Vectors for Word Representation},
	Url = {http://www.aclweb.org/anthology/D14-1162},
	Year = {2014},
	Bdsk-Url-1 = {http://www.aclweb.org/anthology/D14-1162}}

@article{Kiros2015,
	Archiveprefix = {arXiv},
	Author = {Ryan Kiros and Yukun Zhu and Ruslan Salakhutdinov and Richard S. Zemel and Antonio Torralba and Raquel Urtasun and Sanja Fidler},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/KirosZSZTUF15},
	Eprint = {1506.06726},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:48:27 +0200},
	Title = {Skip-Thought Vectors},
	Url = {http://arxiv.org/abs/1506.06726},
	Volume = {abs/1506.06726},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1506.06726}}

@article{Conneau2017,
	Archiveprefix = {arXiv},
	Author = {Alexis Conneau and Douwe Kiela and Holger Schwenk and Lo{\"{\i}}c Barrault and Antoine Bordes},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/ConneauKSBB17},
	Eprint = {1705.02364},
	Journal = {CoRR},
	Title = {Supervised Learning of Universal Sentence Representations from Natural Language Inference Data},
	Url = {http://arxiv.org/abs/1705.02364},
	Volume = {abs/1705.02364},
	Year = {2017},
	Bdsk-Url-1 = {http://arxiv.org/abs/1705.02364}}

@article{Cer2018,
	Archiveprefix = {arXiv},
	Author = {Daniel Cer and Yinfei Yang and Sheng{-}yi Kong and Nan Hua and Nicole Limtiaco and Rhomni St. John and Noah Constant and Mario Guajardo{-}Cespedes and Steve Yuan and Chris Tar and Yun{-}Hsuan Sung and Brian Strope and Ray Kurzweil},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/abs-1803-11175},
	Eprint = {1803.11175},
	Journal = {CoRR},
	Title = {Universal Sentence Encoder},
	Url = {http://arxiv.org/abs/1803.11175},
	Volume = {abs/1803.11175},
	Year = {2018},
	Bdsk-Url-1 = {http://arxiv.org/abs/1803.11175}}

@misc{Ganesan2015,
	Author = {Kavita Ganesan},
	Journal = {Machine Learning, NLP and Text Mining Expert},
	Month = {11},
	Title = {What is text similarity?},
	Url = {kavita-ganesan.com/what-is-text-similarity},
	Year = {2015},
	Bdsk-Url-1 = {kavita-ganesan.com/what-is-text-similarity}}

@article{Gomaa2013,
	Author = {Gomaa, Wael and Fahmy, Aly},
	Doi = {10.5120/11638-7118},
	Journal = {international journal of Computer Applications},
	Month = {04},
	Title = {A Survey of Text Similarity Approaches},
	Volume = {68},
	Year = {2013},
	Bdsk-Url-1 = {https://doi.org/10.5120/11638-7118}}

@article{Pradhan2015,
	Author = {Pradhan, Nitesh and Gyanchandani, Manasi and Wadhvani, Rajesh},
	Doi = {10.5120/21257-4109},
	Journal = {International Journal of Computer Applications},
	Month = {06},
	Pages = {29-34},
	Title = {A Review on Text Similarity Technique used in IR and its Application},
	Volume = {120},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.5120/21257-4109}}

@article{Majumder2016,
	Author = {Majumder, Goutam and Pakray, Dr. Partha and Gelbukh, Alexander and Pinto, David},
	Doi = {10.13053/CyS-20-4-2506},
	Journal = {Computacion y Sistemas},
	Month = {12},
	Pages = {647-665},
	Title = {Semantic Textual Similarity Methods, Tools, and Applications: A Survey},
	Volume = {20},
	Year = {2016},
	Bdsk-Url-1 = {https://doi.org/10.13053/CyS-20-4-2506}}

@inproceedings{Zhang2015,
	Author = {S. {Zhang} and X. {Zheng} and C. {Hu}},
	Booktitle = {2015 IEEE International Conference on Big Data (Big Data)},
	Doi = {10.1109/BigData.2015.7364028},
	Keywords = {social networking (online);text analysis;semantic textual similarity;background information resource;text related research;semantic similarity measure;online social network analysis;similarity computation methods;Semantics;Social network services;Knowledge based systems;Encyclopedias;Electronic publishing;Internet;semantic similarity;semantic textual similarity;social network analysis},
	Month = {Oct},
	Pages = {2362-2367},
	Title = {A survey of semantic similarity and its application to social network analysis},
	Year = {2015},
	Bdsk-Url-1 = {https://doi.org/10.1109/BigData.2015.7364028}}

@misc{Zhu2014,
	Author = {Tian Tian Zhu and Man Lan},
	Title = {ECNU: Leveraging on Ensemble of Heterogeneous Features and Information Enrichment for Cross Level Semantic Similarity Estimation},
	Year = {2014}}

@misc{Jurafsky2018,
	Author = {Dan Jurafsky and James H. Martin},
	Title = {Speech and Language Processing},
	Year = {2018}}

@article{Wang2014,
	Archiveprefix = {arXiv},
	Author = {Jiang Wang and Yang Song and Thomas Leung and Chuck Rosenberg and Jingbin Wang and James Philbin and Bo Chen and Ying Wu},
	Bibsource = {dblp computer science bibliography, https://dblp.org},
	Biburl = {https://dblp.org/rec/bib/journals/corr/WangSLRWPCW14},
	Eprint = {1404.4661},
	Journal = {CoRR},
	Timestamp = {Mon, 13 Aug 2018 16:48:13 +0200},
	Title = {Learning Fine-grained Image Similarity with Deep Ranking},
	Url = {http://arxiv.org/abs/1404.4661},
	Volume = {abs/1404.4661},
	Year = {2014},
	Bdsk-Url-1 = {http://arxiv.org/abs/1404.4661}}

@article{Batista2004,
	Acmid = {1007735},
	Address = {New York, NY, USA},
	Author = {Batista, Gustavo E. A. P. A. and Prati, Ronaldo C. and Monard, Maria Carolina},
	Doi = {10.1145/1007730.1007735},
	Issn = {1931-0145},
	Issue_Date = {June 2004},
	Journal = {SIGKDD Explor. Newsl.},
	Month = jun,
	Number = {1},
	Numpages = {10},
	Pages = {20--29},
	Publisher = {ACM},
	Title = {A Study of the Behavior of Several Methods for Balancing Machine Learning Training Data},
	Url = {http://doi.acm.org/10.1145/1007730.1007735},
	Volume = {6},
	Year = {2004},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1007730.1007735},
	Bdsk-Url-2 = {https://doi.org/10.1145/1007730.1007735}}

@article{He2009,
	Abstract = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
	Author = {H. {He} and E. A. {Garcia}},
	Doi = {10.1109/TKDE.2008.239},
	Issn = {1041-4347},
	Journal = {IEEE Transactions on Knowledge and Data Engineering},
	Keywords = {data mining;decision making;large-scale systems;learning (artificial intelligence);learning;imbalanced data;data availability;large-scale systems;complex systems;networked systems;knowledge discovery;decision making;data engineering;Availability;Large-scale systems;Surveillance;Data security;IP networks;Finance;Data analysis;Decision making;Data engineering;Knowledge representation;Imbalanced learning;classification;sampling methods;cost-sensitive learning;kernel-based learning;active learning;assessment metrics.},
	Month = {Sep.},
	Number = {9},
	Pages = {1263-1284},
	Title = {Learning from Imbalanced Data},
	Volume = {21},
	Year = {2009},
	Bdsk-Url-1 = {https://doi.org/10.1109/TKDE.2008.239}}

@inproceedings{43022,
	Author = {Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
	Booktitle = {Computer Vision and Pattern Recognition (CVPR)},
	Title = {Going Deeper with Convolutions},
	Url = {http://arxiv.org/abs/1409.4842},
	Year = {2015},
	Bdsk-Url-1 = {http://arxiv.org/abs/1409.4842}}
